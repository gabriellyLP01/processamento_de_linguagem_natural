{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ncf7F_beUcUmPkjXLaQKC1-Hd8UkjUXa",
      "authorship_tag": "ABX9TyPzL7GJ4D8KioUmYygzdbmk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriellyLP01/processamento_de_linguagem_natural/blob/main/Aula_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Aula 13 - Processamento de Linguagem Natural"
      ],
      "metadata": {
        "id": "7zA3cMe8nbuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 1: Início do Processamento de Corpus - Leitura do Arquivo"
      ],
      "metadata": {
        "id": "93Jfz-IEnJcl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TEX1XqAHml1H"
      },
      "outputs": [],
      "source": [
        "#Criar uma função para fazer a abertura e leitura do arquivo\n",
        "def ler(nome_arquivo):\n",
        "  arquivo = open(nome_arquivo, 'r', encoding='utf-8')\n",
        "  conteudo_arq = arquivo.read()\n",
        "  arquivo.close()\n",
        "  return conteudo_arq\n",
        "\n",
        "  texto = ler('/content/drive/MyDrive/Colab Notebooks/Linguagem de programação/Ubirajara.txt')\n",
        "  print(len(texto))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 2: buscador de palavras"
      ],
      "metadata": {
        "id": "pPH1JHG0oeAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Criar uma função para fazer a abertura e leitura do arquivo\n",
        "def ler(nome_arquivo):\n",
        "  arquivo = open(nome_arquivo, 'r', encoding='utf-8')\n",
        "  conteudo_arq = arquivo.read()\n",
        "  arquivo.close()\n",
        "  return conteudo_arq\n",
        "\n",
        "  texto = ler('/content/drive/MyDrive/Colab Notebooks/Linguagem de programação/Ubirajara.txt')\n",
        "  print(len(texto))\n",
        "\n",
        "  def buscador(alvo, texto):\n",
        "    texto = texto.replace('\\n', ' ')\n",
        "    texto = texto.replace('\\t', ' ')\n",
        "\n",
        "    ocorrencias = []\n",
        "\n",
        "    encontrando_aqui = texto.find(alvo, 0)\n",
        "    #Se encontra a palavra, informa a posição\n",
        "    #Se não encontrar, inform -1\n",
        "\n",
        "    while encontrando_aqui > 0:\n",
        "      pos_inicial = encontrando_aqui - (40 - len(alvo))\n",
        "      trecho = texto[pos-inicial: pos_inicial + 80]\n",
        "\n",
        "      ocorencias.append(trecho)\n",
        "\n",
        "      encontrando_aqui = texto.find(alvo, encontrando_aqui + 1)\n",
        "\n",
        "      #Inicia a busca a partir da posição anterior +1\n",
        "      #Se encontra a palavra, informa a posição\n",
        "      #Se não encontrar, informa -1\n",
        "\n",
        "    return ocorrencias\n",
        "  resultados = buscador('peito', texto)\n",
        "\n",
        "  for trecho in resultados:\n",
        "    print(trecho)"
      ],
      "metadata": {
        "id": "QF2IEGFKpRD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Etapa 3 - Limpeza do Corpus"
      ],
      "metadata": {
        "id": "gIEA4ojOo-5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  texto = ler('/content/drive/MyDrive/Colab Notebooks/Linguagem de programação/Ubirajara.txt')\n",
        "  print(len(texto))\n",
        "\n",
        "  palavras = texto.split()\n",
        "\n",
        "#Criar uma função para fazer a abertura e leitura do arquivo\n",
        "def ler(nome_arquivo):\n",
        "  arquivo = open(nome_arquivo, 'r', encoding='utf-8')\n",
        "  conteudo_arq = arquivo.read()\n",
        "  arquivo.close()\n",
        "  return conteudo_arq\n",
        "\n",
        "  def buscador(alvo, texto):\n",
        "    texto = texto.replace('\\n', ' ')\n",
        "    texto = texto.replace('\\t', ' ')\n",
        "\n",
        "  def limpar(lista):\n",
        "    lixo = '.,:;?!\"´`^~()[]{}/\\|@#%¨&*-'\n",
        "    quase_limpo = [x.strip(lixo).lower() for x in lista]\n",
        "    return [x for x in quase_limpo if x.isalpha() or '-' not in x]\n",
        "\n",
        "teste = \"Corre-se atrás do carro, corre se o carro for embora.\"\n",
        "word = teste.split\n",
        "print(word)\n",
        "\n",
        "print(limpar(word))\n",
        "\n",
        "print(len(palavras))\n",
        "palavras = limpar(palavras)\n",
        "print(len(palavras))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "baGjw1SFpEoq",
        "outputId": "edb413b8-120b-481c-ef1a-7accb43b818f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "expected an indented block after function definition on line 7 (<ipython-input-6-4220080481>, line 8)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-4220080481>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    arquivo = open(nome_arquivo, 'r', encoding='utf-8')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Etapa 4: Análise de Quantidade de Palavras e Frequência"
      ],
      "metadata": {
        "id": "X8t7eYrWfsna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conhecer a quantidade de palavras e vocabulário\n",
        "vocabulario = set(palavras)\n",
        "len(vocabulario)\n",
        "\n",
        "#Calculando a riqueza textual do corpus\n",
        "riqueza = len(vocabulario) / len(palavras) #6902/36585\n",
        "riqueza\n",
        "\n",
        "#Criar um dicionário deste texto\n",
        "from collections import defaultdict\n",
        "\n",
        "def ocorrencias(listas_palavras):\n",
        "  dicionario = defaultdict(int)\n",
        "  for p in lista_palavras:\n",
        "    dicionario[p] +=1\n",
        "\n",
        "  return dicionario\n",
        "\n",
        "dic = ocorrencias(palavras)\n",
        "mf = sorted(dic.items(), key=lambda tupla:tupla[1], reverse=True)[:50]\n",
        "for palavra, n in mf:\n",
        "  print(palavra, '\\t',n)\n",
        "\n",
        "dic\n",
        "tupla([0],[1])\n",
        "\n",
        "import nltk\n",
        "nltk.donwload('stopwords')\n",
        "vazias = nltk.corpus.stopwords.words('portuguese')\n",
        "\n",
        "frequentes_plenas = [x for x in mf if x[0].lower() not in vazias]\n",
        "frequentes_plenas"
      ],
      "metadata": {
        "id": "3I3Z47sCf4qs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}